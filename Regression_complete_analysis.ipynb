{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5160a103",
   "metadata": {},
   "source": [
    "# Beginners Guide to Regression Analysis and Plot Interpretations\n",
    "\n",
    "Table Of Contents:\n",
    "\n",
    "    Understanding Regression\n",
    "    How Does Regression Work?\n",
    "    Types of Algorithms\n",
    "    Testing of Algorithms\n",
    "\n",
    "Algorithms that we will consider:-\n",
    "\n",
    "    Simple Linear Regression\n",
    "    Multiple Linear Regression\n",
    "    Polynomial Regression\n",
    "    Support Vestor Regression\n",
    "    Decision Tree Regression\n",
    "    Random Forest Regression\n",
    "\n",
    "Lets Start with Understanding what is Regression?\n",
    "\n",
    "Regression is a technique used to predict value of one variable(Dependent Variable) on the basis of other variables(Independent Variables). It is parametric in nature because it makes certain assumptions based on the data set. If the data set follows those assumptions, regression gives incredible results. Otherwise, it struggles to provide convincing accuracy.\n",
    "How Does Regression Work?\n",
    "\n",
    "Regression is a part of supervised learning which basically means that we train our models on the basis of given training data and our model tries to relate between the dependent and the independent variable. It does this using various functions that maps the independent variables to the dependent variables. When the model is completely trained and the error is minumised then we are able to make predictions on testing data as well.\n",
    "We can apply machine learning model by following six steps:-\n",
    "\n",
    "    Indentifying Problem\n",
    "    Analysing Data\n",
    "    Preparing Data\n",
    "    Evaluating Algorithm\n",
    "    Improving Results\n",
    "    Presenting Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ca77e9",
   "metadata": {},
   "source": [
    "## Simple Linear Regression\n",
    "\n",
    "It is a basic and commonly used type of predictive analysis. These regression estimates are used to explain the relationship between one dependent variable and one or more independent variables. y = a*X + b where:\n",
    "\n",
    "    y – Dependent Variable\n",
    "    X – Independent variable\n",
    "    b – intercept\n",
    "    a – Slope\n",
    "\n",
    "Preparing Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ff295c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14cfa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_Dataset = pd.read_csv(\"https://raw.githubusercontent.com/manojcpatil/PythonDemo/master/Data/regression_train_data.csv\")\n",
    "Training_Dataset = Training_Dataset.dropna()\n",
    "X_train = np.array(Training_Dataset.iloc[:, :-1].values) # Independent Variable\n",
    "y_train = np.array(Training_Dataset.iloc[:, 1].values) # Dependent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e004d0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_Dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939dc2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Testing_Dataset = pd.read_csv(\"https://raw.githubusercontent.com/manojcpatil/PythonDemo/master/Data/regression_test_data.csv\")\n",
    "Testing_Dataset = Testing_Dataset.dropna()\n",
    "X_test = np.array(Testing_Dataset.iloc[:, :-1].values) # Independent Variable\n",
    "y_test = np.array(Testing_Dataset.iloc[:, 1].values) # Dependent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261aafa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adb4213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the Model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b05e427",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.anova import anova_lm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "dataset=pd.DataFrame({\n",
    "    'x':X_train.reshape(-1),\n",
    "    'y':y_train\n",
    "})\n",
    "model = ols(\"y ~ x\",dataset).fit()\n",
    "\n",
    "# Print the summary\n",
    "print(model.summary())\n",
    "print(\"\\n model.pvalues:\\n\",model.pvalues,\"\\n\\n\")\n",
    "# Peform analysis of variance on fitted linear model\n",
    "anova_results = anova_lm(model)\n",
    "\n",
    "print('\\nANOVA results')\n",
    "anova_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5c7a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Coefficient %f\"%regressor.coef_)\n",
    "print(\"Intercept %f\"%regressor.intercept_)\n",
    "accuracy = regressor.score(X_test, y_test)\n",
    "print('Accuracy = '+ str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f128bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn')\n",
    "plt.scatter(X_test, y_test, color = 'red', marker = 'o', s = 35, alpha = 0.5,\n",
    "          label = 'Test data')\n",
    "plt.plot(X_train, regressor.predict(X_train), color = 'blue', label='Model Plot')\n",
    "plt.title('Predicted Values vs Inputs')\n",
    "plt.xlabel('Inputs')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.legend(loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e033c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALISE DATA\n",
    "import seaborn as sns\n",
    "df=Training_Dataset\n",
    "sns.pairplot(df) #pairplot\n",
    "sns.distplot(y_train) #distribution plot\n",
    "sns.heatmap(df.corr(), annot=True) #heatmap with values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207340cd",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8185bda4",
   "metadata": {},
   "source": [
    "#### It is also a basic and commonly used type of predictive analysis. These regression estimates are used to explain the relationship between one dependent variable and one or more independent variables. y = b + a1X1 + a2X2 + a3X3 + a4X4 + ... where:\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcddc99",
   "metadata": {},
   "source": [
    " * y – Dependent Variable\n",
    " *    X1, X2, X3, X4 – Independent variable\n",
    " *    b – intercept\n",
    " *    a1, a2, a3 – Slopes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54eb28f",
   "metadata": {},
   "source": [
    "## Preparing Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e5cc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "Preparing Data:\n",
    "\n",
    "dataset=pd.read_csv(\"https://raw.githubusercontent.com/manojcpatil/PythonDemo/master/Data/regression_insurance_data.csv\")\n",
    "print(dataset)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b716cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, :-1] # Independent Variable\n",
    "y = dataset.iloc[:, -1] # Dependent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9844f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALISE DATA\n",
    "\n",
    "df=dataset\n",
    "sns.pairplot(df) #pairplot\n",
    "sns.distplot(y) #distribution plot\n",
    "sns.heatmap(df.corr(), annot=True) #heatmap with values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488ff035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to apply encoding in the dataset as there are words present.\n",
    "# for 'sex' and 'smoker' column we will apply Label Encoding as there are only 2 catagories\n",
    "# for 'region' we will apply OneHot Encoding as there are more than 2 catagories\n",
    "\n",
    "# Label Encoding:\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "X.iloc[:, 1] = le.fit_transform(X.iloc[:, 1])\n",
    "X.iloc[:, 4] = le.fit_transform(X.iloc[:, 4])\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6853d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHot Encoding:\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [5])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8c67e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082c4d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the Model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce322bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = regressor.score(X_test, y_test)\n",
    "print('Accuracy = '+ str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ed9c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8005fadb",
   "metadata": {},
   "source": [
    "## Polynomial Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7982eb7",
   "metadata": {},
   "source": [
    "#### It is a basic and commonly used type of predictive analysis. These regression estimates are used to explain the relationship between one dependent variable and one or more independent variables. y = b + a1X + a1X^2 + a1X^3 + a1X^4 where:\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510d6950",
   "metadata": {},
   "outputs": [],
   "source": [
    "y – Dependent Variable\n",
    "    X1, X2, X3, X4 – Independent variable\n",
    "    b – intercept\n",
    "    a1, a2, a3 – Coefficients of independent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4853b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = pd.read_csv('https://raw.githubusercontent.com/manojcpatil/PythonDemo/master/Data/Regression_polynomial_data.csv')\n",
    "dataset = pd.read_csv('Data/Regression_polynomial_data.csv')\n",
    "\n",
    "X = dataset.iloc[:, :-1] # Independent Variable\n",
    "y = dataset.iloc[:, -1] # Dependent Variable\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9790ec45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the Model\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_reg = PolynomialFeatures(degree = 5)\n",
    "X_poly = poly_reg.fit_transform(X)\n",
    "print(pd.DataFrame(X_poly))\n",
    "lin_reg_2 = LinearRegression()\n",
    "lin_reg_2.fit(X_poly, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4627cc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn')\n",
    "plt.scatter(X, y, color = 'red', marker = 'o', s = 35, alpha = 0.5,\n",
    "          label = 'Test data')\n",
    "plt.plot(X, lin_reg_2.predict(poly_reg.fit_transform(X)), color = 'blue', label='Model Plot')\n",
    "plt.title('Predicted Values vs Inputs')\n",
    "plt.xlabel('Inputs')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.legend(loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7cf8c3",
   "metadata": {},
   "source": [
    "## Support Vector Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e1a44d",
   "metadata": {},
   "source": [
    "#### SVR gives us the flexibility to define how much error is acceptable in our model and will find an appropriate line (or hyperplane in higher dimensions) to fit the data. It uses following constraints- |y - aX| <= e, Where:\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72849aa",
   "metadata": {},
   "source": [
    "* e - maximum error \n",
    "* The points outside the margin are the Support Vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ba2217",
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_Dataset = pd.read_csv(\"https://raw.githubusercontent.com/manojcpatil/PythonDemo/master/Data/regression_train_data.csv\")\n",
    "Training_Dataset = Training_Dataset.dropna()\n",
    "X_train = np.array(Training_Dataset.iloc[:, :-1].values) # Independent Variable\n",
    "y_train = np.array(Training_Dataset.iloc[:, 1].values) # Dependent Variable\n",
    "y_train = y_train.reshape(len(y_train),1)\n",
    "\n",
    "Testing_Dataset = pd.read_csv(\"https://raw.githubusercontent.com/manojcpatil/PythonDemo/master/Data/regression_test_data.csv\")\n",
    "Testing_Dataset = Testing_Dataset.dropna()\n",
    "X_test = np.array(Testing_Dataset.iloc[:, :-1].values) # Independent Variable\n",
    "y_test = np.array(Testing_Dataset.iloc[:, 1].values) # Dependent Variable\n",
    "y_test = y_test.reshape(len(y_test),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0278eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling X and y\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "sc_y = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "y_train = sc_y.fit_transform(y_train.reshape(len(y_train),1))\n",
    "y_test = sc_y.transform(y_test.reshape(len(y_test),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4241eb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the Model\n",
    "from sklearn.svm import SVR\n",
    "regressor = SVR(kernel = 'rbf')\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df02fdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = regressor.score(X_test, y_test)\n",
    "print('Accuracy = '+ str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9555a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.predict(X_test).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34ef838",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(sc_X.inverse_transform(X_test), sc_y.inverse_transform(y_test), color = 'red', marker = 'o', s = 35, alpha = 0.5, label = 'Test data')\n",
    "plt.plot(sc_X.inverse_transform(X_test), sc_y.inverse_transform(regressor.predict(X_test).reshape(-1,1)),color = 'blue', label='Model Plot')\n",
    "plt.title('Predicted Values vs Inputs')\n",
    "plt.xlabel('Inputs')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.legend(loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3b6f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the Model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor1 = LinearRegression()\n",
    "regressor1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d63c4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(sc_X.inverse_transform(X_test), sc_y.inverse_transform(y_test), color = 'red', marker = 'o', s = 35, alpha = 0.5, label = 'Test data')\n",
    "plt.plot(sc_X.inverse_transform(X_test), sc_y.inverse_transform(regressor1.predict(X_test).reshape(-1,1)),color = 'blue', label='SVR Model Plot')\n",
    "plt.plot(sc_X.inverse_transform(X_test), sc_y.inverse_transform(regressor1.predict(X_test).reshape(-1,1)),color = 'green', label='Linear Model Plot')\n",
    "plt.title('Predicted Values vs Inputs')\n",
    "plt.xlabel('Inputs')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.legend(loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7067cb11",
   "metadata": {},
   "source": [
    "## Decision Tree Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad91d04",
   "metadata": {},
   "source": [
    "#### Decision tree builds regression or classification models in the form of a tree structure. It breaks down a dataset into smaller and smaller subsets while at the same time an associated decision tree is incrementally developed. The final result is a tree with decision nodes and leaf nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6573de15",
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_Dataset = pd.read_csv(\"https://raw.githubusercontent.com/manojcpatil/PythonDemo/master/Data/regression_train_data.csv\")\n",
    "Training_Dataset = Training_Dataset.dropna()\n",
    "X_train = np.array(Training_Dataset.iloc[:, :-1].values) # Independent Variable\n",
    "y_train = np.array(Training_Dataset.iloc[:, 1].values) # Dependent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bad4718",
   "metadata": {},
   "outputs": [],
   "source": [
    "Testing_Dataset = pd.read_csv(\"https://raw.githubusercontent.com/manojcpatil/PythonDemo/master/Data/regression_test_data.csv\")\n",
    "Testing_Dataset = Testing_Dataset.dropna()\n",
    "X_test = np.array(Testing_Dataset.iloc[:, :-1].values) # Independent Variable\n",
    "y_test = np.array(Testing_Dataset.iloc[:, 1].values) # Dependent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa18b422",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "regressor = DecisionTreeRegressor(max_depth=5,random_state = 0)\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d34e8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = regressor.score(X_test, y_test)\n",
    "print('Accuracy = '+ str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e27cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_grid = np.arange(min(X_test), max(X_test), 0.01)\n",
    "X_grid = X_grid.reshape((len(X_grid), 1))\n",
    "plt.scatter(X_test, y_test, color = 'red', marker = 'o', s = 35, alpha = 0.5,\n",
    "          label = 'Test data')\n",
    "plt.plot(X_grid, regressor.predict(X_grid), color = 'blue', label='Model Plot')\n",
    "plt.title('Predicted Values vs Inputs')\n",
    "plt.xlabel('Inputs')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.legend(loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cea5171",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea22ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random Forest combines multiple trees to predict the class of the dataset, it is possible that some decision trees may predict the correct output, while others may not. But together, all the trees predict the correct output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47853885",
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_Dataset = pd.read_csv(\"https://raw.githubusercontent.com/manojcpatil/PythonDemo/master/Data/regression_train_data.csv\")\n",
    "Training_Dataset = Training_Dataset.dropna()\n",
    "X_train = np.array(Training_Dataset.iloc[:, :-1].values) # Independent Variable\n",
    "y_train = np.array(Training_Dataset.iloc[:, 1].values) # Dependent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e04c3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "Testing_Dataset = pd.read_csv(\"https://raw.githubusercontent.com/manojcpatil/PythonDemo/master/Data/regression_test_data.csv\")\n",
    "Testing_Dataset = Testing_Dataset.dropna()\n",
    "X_test = np.array(Testing_Dataset.iloc[:, :-1].values) # Independent Variable\n",
    "y_test = np.array(Testing_Dataset.iloc[:, 1].values) # Dependent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d40289",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators = 10, random_state = 0)\n",
    "regressor.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76aacf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = regressor.score(X_test, y_test)\n",
    "print('Accuracy = '+ str(accuracy))\n",
    "\n",
    "X_grid = np.arange(min(X_test), max(X_test), 0.01)\n",
    "X_grid = X_grid.reshape((len(X_grid), 1))\n",
    "plt.scatter(X_test, y_test, c = 'red', marker = 'o', s = 35, alpha = 0.5,\n",
    "          label = 'Test data')\n",
    "plt.plot(X_grid, regressor.predict(X_grid), color = 'blue', label='Model Plot')\n",
    "plt.title('Predicted Values vs Inputs')\n",
    "plt.xlabel('Position level')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.legend(loc = 'upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
